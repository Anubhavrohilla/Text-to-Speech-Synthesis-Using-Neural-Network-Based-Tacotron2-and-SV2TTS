{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing English Audio into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:29.638130Z",
     "start_time": "2024-05-31T00:55:29.622503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/suno-ai/bark.git (from -r requirements.txt (line 13))\n",
      "  Cloning https://github.com/suno-ai/bark.git to c:\\users\\kushr\\appdata\\local\\temp\\pip-req-build-3qzwefy2\n",
      "  Resolved https://github.com/suno-ai/bark.git to commit f4f32d4cd480dfec1c245d258174bc9bde3c2148\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting git+https://github.com/huggingface/transformers.git (from -r requirements.txt (line 16))\n",
      "  Cloning https://github.com/huggingface/transformers.git to c:\\users\\kushr\\appdata\\local\\temp\\pip-req-build-64go9oxe\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 6bd511a45a58eb02bd59cf447141a2af428747a4\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ffmpeg-python in e:\\new folder\\lib\\site-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: openai-whisper in e:\\new folder\\lib\\site-packages (from -r requirements.txt (line 7)) (20231117)\n",
      "Requirement already satisfied: googletrans==4.0.0-rc1 in e:\\new folder\\lib\\site-packages (from -r requirements.txt (line 10)) (4.0.0rc1)\n",
      "Requirement already satisfied: TTS in e:\\new folder\\lib\\site-packages (from -r requirements.txt (line 19)) (0.22.0)\n",
      "Requirement already satisfied: httpx==0.13.3 in e:\\new folder\\lib\\site-packages (from googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (0.13.3)\n",
      "Requirement already satisfied: certifi in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (2024.2.2)\n",
      "Requirement already satisfied: hstspreload in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (2024.5.1)\n",
      "Requirement already satisfied: sniffio in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in e:\\new folder\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in e:\\new folder\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in e:\\new folder\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in e:\\new folder\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in e:\\new folder\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: future in e:\\new folder\\lib\\site-packages (from ffmpeg-python->-r requirements.txt (line 4)) (0.18.3)\n",
      "Requirement already satisfied: numba in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (0.59.0)\n",
      "Requirement already satisfied: numpy in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: torch in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (10.1.0)\n",
      "Requirement already satisfied: tiktoken in e:\\new folder\\lib\\site-packages (from openai-whisper->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: boto3 in e:\\new folder\\lib\\site-packages (from suno-bark==0.0.1a0->-r requirements.txt (line 13)) (1.34.116)\n",
      "Requirement already satisfied: encodec in e:\\new folder\\lib\\site-packages (from suno-bark==0.0.1a0->-r requirements.txt (line 13)) (0.1.1)\n",
      "Requirement already satisfied: funcy in e:\\new folder\\lib\\site-packages (from suno-bark==0.0.1a0->-r requirements.txt (line 13)) (2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.1 in e:\\new folder\\lib\\site-packages (from suno-bark==0.0.1a0->-r requirements.txt (line 13)) (0.23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git 'C:\\Users\\kushr\\AppData\\Local\\Temp\\pip-req-build-3qzwefy2'\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\kushr\\AppData\\Local\\Temp\\pip-req-build-64go9oxe'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 230, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 148, in _add_to_criteria\n",
      "    matches = self._p.find_matches(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\provider.py\", line 231, in find_matches\n",
      "    return self._factory.find_candidates(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 434, in find_candidates\n",
      "    return self._iter_found_candidates(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 325, in _iter_found_candidates\n",
      "    _get_installed_candidate(),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 271, in _get_installed_candidate\n",
      "    if not specifier.contains(installed_dist.version, prereleases=True):\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py\", line 177, in version\n",
      "    return parse_version(self._dist.version)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 49, in parse\n",
      "    return Version(version)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\New folder\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 264, in __init__\n",
      "    match = self._regex.search(version)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:33.585707Z",
     "start_time": "2024-05-31T00:55:29.638130Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-u4nJve_5yJ",
    "outputId": "933fdf42-3caf-4a1a-fdce-51ff11e4f5e0"
   },
   "outputs": [],
   "source": [
    "# Import whisper library to convert audio to text\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:45.874035Z",
     "start_time": "2024-05-31T00:55:33.585707Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yloQynPSCItQ",
    "outputId": "4605791f-ddba-46f9-fa1c-47951dc8e859"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize a base model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Transcribe audio using the model\n",
    "result = model.transcribe(\"Elon Musk audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:45.890059Z",
     "start_time": "2024-05-31T00:55:45.874035Z"
    },
    "id": "Bz0gSQuTCS7V"
   },
   "outputs": [],
   "source": [
    "# Save the transcripted text into a text file\n",
    "with open(\"transcript.txt\",\"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:45.905695Z",
     "start_time": "2024-05-31T00:55:45.890059Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "W61jfn3TCV3I",
    "outputId": "3bdce328-4291-45be-b5bc-7861c2085798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm actually incredibly excited about the future of India. I think India has more promise than any large country in the world. He really cares about India because he's pushing us to make significant investments in India which it is something that we intend to do and we're just trying to figure out the right timing. It was a fantastic meeting with the Prime Minister and I like him quite a lot. He visited our free want factory several years ago and so we're now knowing each other for a while. I can say he really wants to do the right thing for India. He wants to be open, he wants to be supportive of new companies and obviously but in the same time make sure it accrues to India's advantage which is obviously that's the job. I'm saying I am a fan of Modi.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the transcripted text\n",
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Translating Text from English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:46.128529Z",
     "start_time": "2024-05-31T00:55:45.905695Z"
    },
    "id": "p6qR-zVLCYrs"
   },
   "outputs": [],
   "source": [
    "# Import Translator from google translator to translate text from english to hindi\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:46.792112Z",
     "start_time": "2024-05-31T00:55:46.128529Z"
    },
    "id": "k9Moo_MSCbl-"
   },
   "outputs": [],
   "source": [
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "# Define the text to be translated\n",
    "text = result[\"text\"]\n",
    "\n",
    "# en is the code for the English Language\n",
    "source_lan = \"en\"\n",
    "# hi is the code for the Hindi Language\n",
    "translated_to= \"hi\" \n",
    "\n",
    "# Translate the text from engligh to hindi using translator\n",
    "translated_text = translator.translate(text, src=source_lan, dest=translated_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:46.807749Z",
     "start_time": "2024-05-31T00:55:46.792112Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "_BrV7MqiCiaa",
    "outputId": "b64b1e17-84a8-458e-d3e6-1f1f1899e614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं वास्तव में भारत के भविष्य के बारे में अविश्वसनीय रूप से उत्साहित हूं।मुझे लगता है कि भारत में दुनिया के किसी भी बड़े देश की तुलना में अधिक वादा है।वह वास्तव में भारत के बारे में परवाह करता है क्योंकि वह हमें भारत में महत्वपूर्ण निवेश करने के लिए प्रेरित कर रहा है जो कि यह कुछ ऐसा है जिसे हम करना चाहते हैं और हम सिर्फ सही समय का पता लगाने की कोशिश कर रहे हैं।यह प्रधानमंत्री के साथ एक शानदार बैठक थी और मैं उन्हें काफी पसंद करता हूं।उन्होंने कई साल पहले हमारे फ्री वांट फैक्ट्री का दौरा किया था और इसलिए हम अब एक -दूसरे को थोड़ी देर के लिए जानते हैं।मैं कह सकता हूं कि वह वास्तव में भारत के लिए सही काम करना चाहता है।वह खुला रहना चाहता है, वह नई कंपनियों का समर्थन करना चाहता है और जाहिर है लेकिन एक ही समय में यह सुनिश्चित करें कि यह भारत के लाभ के लिए अर्जित करता है जो जाहिर है कि यह काम है।मैं कह रहा हूं कि मैं मोदी का प्रशंसक हूं।'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the translated_text\n",
    "translated_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:55:56.081533Z",
     "start_time": "2024-05-31T00:55:46.807749Z"
    },
    "id": "wjh17T6GCnvO"
   },
   "outputs": [],
   "source": [
    "# Import TTS for voice synthesis\n",
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:56:00.827599Z",
     "start_time": "2024-05-31T00:55:56.081533Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:56:01.486350Z",
     "start_time": "2024-05-31T00:56:00.827599Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmXCKhCaCtfY",
    "outputId": "c113f4b4-83e4-4980-ac38-ba8cd2e38333"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'dataset' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize TTS model with Hindi language\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m api \u001b[38;5;241m=\u001b[39m TTS(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_models/hin/fairseq/vits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Voice clone with the translated hindi text and save the output\u001b[39;00m\n\u001b[0;32m      5\u001b[0m api\u001b[38;5;241m.\u001b[39mtts_with_vc_to_file(\n\u001b[0;32m      6\u001b[0m     translated_text\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m      7\u001b[0m     speaker_wav\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElon Musk audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElon Musk audio (Hindi).wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\TTS\\api.py:74\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[1;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_tts_model_by_name(model_name, gpu)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_conversion_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\TTS\\api.py:171\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[1;34m(self, model_name, gpu)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m--> 171\u001b[0m model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_model_by_name(\n\u001b[0;32m    172\u001b[0m     model_name\n\u001b[0;32m    173\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# init synthesizer\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# None values are fetch from the model\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m Synthesizer(\n\u001b[0;32m    178\u001b[0m     tts_checkpoint\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m    179\u001b[0m     tts_config_path\u001b[38;5;241m=\u001b[39mconfig_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m     use_cuda\u001b[38;5;241m=\u001b[39mgpu,\n\u001b[0;32m    188\u001b[0m )\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\TTS\\api.py:129\u001b[0m, in \u001b[0;36mTTS.download_model_by_name\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_model_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 129\u001b[0m     model_path, config_path, model_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39mdownload_model(model_name)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfairseq\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name \u001b[38;5;129;01mor\u001b[39;00m (model_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_url\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;66;03m# return model directory if there are multiple files\u001b[39;00m\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;66;03m# we assume that the model knows how to load itself\u001b[39;00m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, model_path\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\TTS\\utils\\manage.py:385\u001b[0m, in \u001b[0;36mModelManager.download_model\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download model files given the full model name.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    Model name is in the format\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        'type/language/dataset/model'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m        model_name (str): model name as explained above.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     model_item, model_full_name, model, md5sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_model_item(model_name)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# set the model specific output path\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_prefix, model_full_name)\n",
      "File \u001b[1;32mE:\\New folder\\Lib\\site-packages\\TTS\\utils\\manage.py:304\u001b[0m, in \u001b[0;36mModelManager._set_model_item\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    301\u001b[0m     model_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dict[model_type][lang][dataset][model]\n\u001b[0;32m    302\u001b[0m     model_item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model_type\n\u001b[1;32m--> 304\u001b[0m model_full_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m md5hash \u001b[38;5;241m=\u001b[39m model_item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_item \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    306\u001b[0m model_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_model_url(model_item)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'dataset' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# Initialize TTS model with Hindi language\n",
    "api = TTS(\"tts_models/hin/fairseq/vits\")\n",
    "\n",
    "# Voice clone with the translated hindi text and save the output\n",
    "api.tts_with_vc_to_file(\n",
    "    translated_text.text,\n",
    "    speaker_wav=\"Elon Musk audio.wav\",\n",
    "    file_path=\"Elon Musk audio (Hindi).wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T00:56:01.486350Z",
     "start_time": "2024-05-31T00:56:01.486350Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
